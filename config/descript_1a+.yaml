train_mode: 'both' # 'descriptor' or 'both'

# # cache files to train using
# denoiser_cache_tags:
#     - '20190322_1439'
denoiser_cache_tags: []

descriptor_arch:
  model_revision: '1'
  model_params:
  optim_name: 'sgd' #'adam'
  optim_params:
    lr: 0.005 #0.001 #0.01 #0.1 #5.0e-6 #1.0e-5
  loss_name: mean_absolute_error
  future_params:



denoiser_arch:
  model_revision: '1b'
  model_params:
    top_lvl_channels: 64 #16
    conv_repeats: 3 #1
  optim_name: 'adam'
  optim_params:
    lr: 5.0e-4
    #decay: 1.0e-6
    epsilon: 1.0e-6
  metric_name: 'mae'
  loss_name: 'dssim_and_mae' #'dssim' #'mean_absolute_error'
  future_params:
    loss_params:
      k1: 0.01
      k2: 0.03
      kernel_size: 3
      max_value: 100000 # best one after sweep! default: 1.0
      alpha_dssim: 0.5 #0.8 #0.5 #0.1 #0.01 #0.99 # 0.1 is best after sweep!

training:
  denoiser_epochs: 1
  descriptor_epochs: 10
  epochs: 5 #10 #1 #2 #0
  epoch_reshuffle: True


dataloader:
  denoiser:
    train_batch_size: 100
    val_batch_size: 2048
  descriptor:
    train_batch_size: 100 #200 #500 #100
    val_batch_size: 2048
    use_clean: False
    return_img_lbl_pair: False
    data_loader_params:
      shuffle: True # a default param so to avoid empty dict