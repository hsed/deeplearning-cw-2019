train_mode: 'both' # 'descriptor' or 'both'

# cache files to train using
# denoiser_cache_tags:
#     - '20190322_1439'

descriptor_arch:
  model_revision: '1f' #'1' #'1c' #'1b' #'1'
  model_params:
    #
  optim_name: 'sgd' #'adam'
  optim_params:
    #
    lr: 0.01 #0.005 #0.001 #0.01 #0.1 #5.0e-6 #1.0e-5
  loss_name: 'semihard'
  future_params:


denoiser_arch:
  model_revision: '1b'
  model_params:
    top_lvl_channels: 64 #16
    conv_repeats: 3 #1
  optim_name: 'adam'
  optim_params:
    lr: 5.0e-4
    #decay: 1.0e-6
    epsilon: 1.0e-6
  metric_name: 'mae'
  loss_name: 'dssim_and_mae' #'dssim' #'mean_absolute_error'
  future_params:
    loss_params:
      k1: 0.01
      k2: 0.03
      kernel_size: 3
      max_value: 100000
      alpha_dssim: 0.5


training:
  denoiser_epochs: 1
  descriptor_epochs: 20
  epochs: 5 #10 #1 #2 #0
  early_stopping_interval: 10
  epoch_reshuffle: True


dataloader:
  denoiser:
    train_batch_size: 100
    val_batch_size: 2048
  descriptor:
    train_batch_size: 100 #200 #500 #100
    val_batch_size: 100 #512 #1024 #2048
    use_clean: False
    #train_triplets: 1000 #100000
    #test_triplets: 100 #10000
    return_img_lbl_pair: True
    data_loader_params:
      shuffle: True # a default param so to avoid empty dict